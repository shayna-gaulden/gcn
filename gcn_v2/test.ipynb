{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "print(\"Size of adjacency matrix = \" + str(adj.shape))\n",
    "print(\"Size of feature matrix = \" + str(features.shape))     # expected to be sparse\n",
    "print(\"Size of label matrix = \" + str(train_mask.shape))\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)\n",
    "print(train_mask.shape)\n",
    "print(val_mask.shape)\n",
    "```\n",
    "produces these results:\n",
    "```\n",
    "Size of adjacency matrix = (2708, 2708)\n",
    "Size of feature matrix = (2708, 1433)\n",
    "Size of label matrix = (2708,)\n",
    "(2708, 7)\n",
    "(2708, 7)\n",
    "(2708, 7)\n",
    "(2708,)\n",
    "(2708,)\n",
    "```\n",
    "\n",
    "A mask is used which is why they are all the same size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Hamming loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[False  True  True  True False]\n",
      " [False False False  True  True]\n",
      " [ True False  True False False]], shape=(3, 5), dtype=bool)\n",
      "tf.Tensor(\n",
      "[[False  True  True False  True]\n",
      " [False False False False  True]\n",
      " [ True False  True False False]], shape=(3, 5), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "# Short demonstation of how Hamming loss will be calculated for multiple vectors\n",
    "import tensorflow as tf\n",
    "\n",
    "# define a threshold\n",
    "thresh = tf.constant(0.5)\n",
    "sample_output = tf.constant([[0.23, 0.98, 0.78, 0.52, 0.48], [0.1, 0.2, 0.3, 0.6, 0.9], [\n",
    "                     0.9, 0.1, 0.99, 0.0, 0.03]])      # sample logit output\n",
    "# prediciton based on output and threshold\n",
    "preds = tf.math.greater(sample_output, thresh, name=None)\n",
    "print(preds)\n",
    "\n",
    "# define samplel labels\n",
    "labels = tf.constant([[0, 1, 1, 0, 1], [0, 0, 0, 0, 1], [1, 0, 1, 0, 0]])\n",
    "bool_labels = tf.equal(labels, tf.constant(\n",
    "    1))               # transform to bool\n",
    "print(bool_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions\n",
      "tf.Tensor(\n",
      "[[False  True  True  True False]\n",
      " [False False False  True  True]\n",
      " [ True False  True False False]], shape=(3, 5), dtype=bool)\n",
      "Labels\n",
      "tf.Tensor(\n",
      "[[False  True  True False  True]\n",
      " [False False False False  True]\n",
      " [ True False  True False False]], shape=(3, 5), dtype=bool)\n",
      "tf.Tensor(\n",
      "[[False False False  True  True]\n",
      " [False False False  True False]\n",
      " [False False False False False]], shape=(3, 5), dtype=bool)\n",
      "Hamming Loss before mask\n",
      "tf.Tensor([0.4 0.2 0. ], shape=(3,), dtype=float32)\n",
      "tf.Tensor(0.3, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# trying to fix pre masking hamming loss shape\n",
    "def masked_hamming_loss(outputs, labels, mask):\n",
    "    \"\"\"hamming loss with masking.\"\"\"\n",
    "    # make prediction\n",
    "    # define a threshold\n",
    "    thresh = tf.constant(0.5)\n",
    "    # prediciton based on output and threshold\n",
    "    preds = tf.math.greater(outputs, thresh, name=None)\n",
    "\n",
    "    print(\"Predictions\")\n",
    "    print(preds)\n",
    "   \n",
    "    bool_labels = tf.equal(tf.cast(labels, tf.int32),\n",
    "                           tf.constant(1))  # transform to bool\n",
    "\n",
    "    print(\"Labels\")\n",
    "    print(bool_labels)\n",
    "\n",
    "    # find where there are mistakes\n",
    "    exclusive_or = tf.math.not_equal(bool_labels, preds)\n",
    "    print(exclusive_or)\n",
    "\n",
    "    # count how many true in exclusive or of label (how many are wrong)\n",
    "    ham_loss_all = tf.math.reduce_mean(\n",
    "        tf.cast(exclusive_or, tf.float32), axis=1)\n",
    "        \n",
    "    print(\"Hamming Loss before mask\")\n",
    "    print(ham_loss_all)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    mask /= tf.reduce_mean(input_tensor=mask)\n",
    "    ham_loss_all *= mask\n",
    "    return tf.reduce_mean(input_tensor=ham_loss_all)\n",
    "\n",
    "\n",
    "print(masked_hamming_loss(sample_output, labels, mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Alpha Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predited labels\n",
      "tf.Tensor(\n",
      "[[False  True  True  True False]\n",
      " [False False False  True  True]\n",
      " [ True False  True False False]], shape=(3, 5), dtype=bool)\n",
      "True labels\n",
      "tf.Tensor(\n",
      "[[False  True  True False  True]\n",
      " [False False False False  True]\n",
      " [ True False  True False False]], shape=(3, 5), dtype=bool)\n",
      "True if mistake\n",
      "tf.Tensor(\n",
      "[[False False False  True  True]\n",
      " [False False False  True False]\n",
      " [False False False False False]], shape=(3, 5), dtype=bool)\n",
      "True if there is a label in predicted or true set\n",
      "tf.Tensor(\n",
      "[[False  True  True  True  True]\n",
      " [False False False  True  True]\n",
      " [ True False  True False False]], shape=(3, 5), dtype=bool)\n",
      "tf.Tensor([2 1 0], shape=(3,), dtype=int32)\n",
      "tf.Tensor([4 2 2], shape=(3,), dtype=int32)\n",
      "tf.Tensor([0.5 0.5 0. ], shape=(3,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# Short demonstation of how alpha eval loss will be calculated for multiple vectors\n",
    "import tensorflow as tf\n",
    "\n",
    "# define a threshold\n",
    "thresh = tf.constant(0.5)\n",
    "sample_output = tf.constant([[0.23, 0.98, 0.78, 0.52, 0.48], [0.1, 0.2, 0.3, 0.6, 0.9], [\n",
    "    0.9, 0.1, 0.99, 0.0, 0.03]])      # sample logit output\n",
    "# prediciton based on output and threshold\n",
    "preds = tf.math.greater(sample_output, thresh, name=None)\n",
    "print(\"Predited labels\")\n",
    "print(preds)\n",
    "\n",
    "# define samplel labels\n",
    "labels = tf.constant([[0, 1, 1, 0, 1], [0, 0, 0, 0, 1], [1, 0, 1, 0, 0]])\n",
    "bool_labels = tf.equal(labels, tf.constant(\n",
    "    1))               # transform to bool\n",
    "print(\"True labels\")\n",
    "print(bool_labels)\n",
    "\n",
    "# find where there are mistakes\n",
    "exclusive_or = tf.math.not_equal(bool_labels, preds)\n",
    "print(\"True if mistake\")\n",
    "print(exclusive_or)\n",
    "\n",
    "# find all labels\n",
    "print(\"True if there is a label in predicted or true set\")\n",
    "union = tf.math.logical_or(bool_labels, preds)\n",
    "print(union)\n",
    "\n",
    "# divide\n",
    "print(tf.reduce_sum(tf.cast(exclusive_or, dtype=tf.int32), axis=1))\n",
    "print(tf.reduce_sum(tf.cast(union, dtype=tf.int32), axis=1))\n",
    "alpha_eval = tf.divide_no_nan(tf.reduce_sum(tf.cast(exclusive_or, dtype=tf.int32), axis=1),\n",
    "          tf.reduce_sum(tf.cast(union, dtype=tf.int32), axis=1))\n",
    "\n",
    "print(alpha_eval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.8147452  0.31867993 0.3773441  0.9865731  0.48167482]\n",
      " [0.7443967  0.79813886 0.8543552  1.037488   0.34115386]\n",
      " [0.34115386 0.7443967  0.31596094 0.6931472  0.70825964]], shape=(3, 5), dtype=float32)\n",
      "tf.Tensor([4.482969  1.1741972 2.3392463], shape=(3,), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=2.6654708>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def masked_softmax_cross_entropy(preds, labels):\n",
    "    \"\"\"Softmax cross-entropy loss with masking.\"\"\"\n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        logits=preds, labels=tf.cast(labels,dtype=tf.float32))\n",
    "    print(loss)\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(\n",
    "        logits=preds, labels=tf.cast(labels, dtype=tf.float32))\n",
    "    print(loss)\n",
    "    #mask = tf.cast(mask, dtype=tf.float32)\n",
    "    #mask /= tf.reduce_mean(mask)\n",
    "    #loss *= mask\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "\n",
    "masked_softmax_cross_entropy(sample_output, labels) # sigmoid loss is returning a matrix but softmax loss returns a vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.70320445, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "mask = tf.constant([1, 1, 0])\n",
    "\n",
    "# with predictions\n",
    "def masked_sigmoid_cross_entropy(outputs, labels, mask):\n",
    "    \"\"\"Softmax cross-entropy loss with masking.\"\"\"\n",
    "    # define a threshold\n",
    "    thresh = tf.constant(0.5)\n",
    "    # prediciton based on output and threshold\n",
    "    preds = tf.math.greater(outputs, thresh, name=None)\n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        logits=tf.cast(preds, dtype=tf.float32), labels=tf.cast(labels, dtype=tf.float32))\n",
    "\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    mask /= tf.reduce_mean(mask)\n",
    "\n",
    "    loss = tf.multiply(loss, tf.reshape(mask, (-1, 1)))\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "\n",
    "# sigmoid loss is returning a matrix but softmax loss returns a vector\n",
    "print(masked_sigmoid_cross_entropy(sample_output, labels, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.675455, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "mask = tf.constant([1, 1, 0])\n",
    "\n",
    "# with OUT predictions\n",
    "def masked_sigmoid_cross_entropy(outputs, labels, mask):\n",
    "    \"\"\"Softmax cross-entropy loss with masking.\"\"\"\n",
    "\n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        logits=tf.cast(outputs, dtype=tf.float32), labels=tf.cast(labels, dtype=tf.float32))\n",
    "\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    mask /= tf.reduce_mean(mask)\n",
    "\n",
    "    loss = tf.multiply(loss, tf.reshape(mask, (-1, 1)))\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "\n",
    "# sigmoid loss is returning a matrix but softmax loss returns a vector\n",
    "print(masked_sigmoid_cross_entropy(sample_output, labels, mask))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3fa3b7cf96bac197797867e8b125ebe015f55caaa4d9e9c2464cd065023f3387"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('python3_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
